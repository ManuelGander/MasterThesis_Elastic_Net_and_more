{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ee32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i0=0\n",
    "i1=0\n",
    "i2=0\n",
    "i3=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8cf13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "sys.path.append('/home/icb/manuel.gander/Atl/notebooks/')\n",
    "import utils\n",
    "import importlib\n",
    "utils = importlib.reload(utils)\n",
    "device = 'cuda'\n",
    "Path = '/home/icb/manuel.gander/Atl/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4d58a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['RNA', 'identity', 'atl_only_full', 'atl_only_phos']\n",
    "dataset = datasets[i0]\n",
    "\n",
    "n_componentss = [2,5,10,30]\n",
    "n_components = n_componentss[i1]\n",
    "\n",
    "methods = ['als', 'kino', 'rdkit']\n",
    "method = methods[i2]\n",
    "\n",
    "dense_dims = [5,10,20,50]\n",
    "dense_dim = dense_dims[i3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ae66849",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv_train = pd.read_pickle(f'{dataset}_dfv_train.pkl')\n",
    "dfv_test = pd.read_pickle(f'{dataset}_dfv_test.pkl')\n",
    "\n",
    "Za = pd.read_pickle(f'{dataset}_ALS_drug_embedding.pkl')\n",
    "Dai = dict(zip([str(a) for a in Za.index], range(len(Za))))\n",
    "Zan = Za.values\n",
    "Zk = pd.read_pickle(f'{dataset}_Kinobead_drug_embedding.pkl')\n",
    "Dki = dict(zip([str(a) for a in Zk.index], range(len(Zk))))\n",
    "Zkn = Zk.values\n",
    "Zr = pd.read_pickle(f'{dataset}_rdkit_drug_embedding.pkl')\n",
    "Dri = dict(zip([str(a) for a in Zr.index], range(len(Zr))))\n",
    "Zrn = Zr.values\n",
    "\n",
    "# only keep the drugs that are shared between all of them to compare it all properly\n",
    "drugs = sorted([str(a) for a in set(Dai.keys())&set(Dki.keys())&set(Dri.keys())])\n",
    "\n",
    "dfv_train = dfv_train[dfv_train['PubChem_CID'].isin(drugs)].copy()\n",
    "dfv_test = dfv_test[dfv_test['PubChem_CID'].isin(drugs)].copy()\n",
    "dfv_train_mean = dfv_train[['PubChem_CID', 'AUC']].groupby(['PubChem_CID']).mean().reset_index().copy()\n",
    "Dvm = dict(zip(dfv_train_mean.PubChem_CID, dfv_train_mean.AUC))\n",
    "dfv_test['mean_AUC'] = dfv_test['PubChem_CID'].map(Dvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc019d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get torch arrays of feature data\n",
    "with open(f'/home/icb/manuel.gander/Atl/data/pcas/{dataset}_{n_components}.pkl', 'rb') as file:\n",
    "    D_prot2, features, cellos = pickle.load(file)\n",
    "P = pd.DataFrame(np.vstack(list(D_prot2.values())), index=[a.split('_')[0] for a in D_prot2.keys()])\n",
    "Dpi = dict(zip(P.index, range(len(P))))\n",
    "Pn = P.values\n",
    "\n",
    "\n",
    "if method == 'als':\n",
    "    Di = Dai\n",
    "    Z = Zan\n",
    "elif method == 'kino':\n",
    "    Di = Dki\n",
    "    Z = Zkn\n",
    "elif method == 'rdkit':\n",
    "    Di = Dri\n",
    "    Z = Zrn\n",
    "    \n",
    "D = Z[dfv_train['PubChem_CID'].map(Di),:].copy()\n",
    "C = Pn[dfv_train['Cello'].map(Dpi),:]\n",
    "\n",
    "D2 = Z[dfv_test['PubChem_CID'].map(Di),:].copy()\n",
    "C2 = Pn[dfv_test['Cello'].map(Dpi),:]\n",
    "\n",
    "\n",
    "Dt = torch.tensor(D, device=device, dtype=torch.float32)\n",
    "Ct = torch.tensor(C, device=device, dtype=torch.float32)\n",
    "vt = torch.tensor(dfv_train['AUC'].values, device=device, dtype=torch.float32)\n",
    "\n",
    "D2t = torch.tensor(D2, device=device, dtype=torch.float32)\n",
    "C2t = torch.tensor(C2, device=device, dtype=torch.float32)\n",
    "v2t = torch.tensor(dfv_test['AUC'].values, device=device, dtype=torch.float32)\n",
    "v2mt = torch.tensor(dfv_test['mean_AUC'].values, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa2962e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (d1): Linear(in_features=2, out_features=5, bias=True)\n",
      "  (d2): Linear(in_features=5, out_features=5, bias=True)\n",
      "  (d3): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (d4): Linear(in_features=5, out_features=5, bias=True)\n",
      "  (d5): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.d1 = nn.Linear(Ct.shape[1], dense_dim)\n",
    "        self.d2 = nn.Linear(Dt.shape[1], dense_dim)\n",
    "        self.d3 = nn.Linear(dense_dim*2, dense_dim)\n",
    "        self.d4 = nn.Linear(dense_dim, dense_dim)\n",
    "        self.d5 = nn.Linear(dense_dim, 1)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        x = F.relu(self.d1(x))\n",
    "        y = F.relu(self.d2(y))\n",
    "        z = torch.concat([x,y], axis=1)\n",
    "        z = F.relu(self.d3(z))\n",
    "        z = F.relu(self.d4(z))\n",
    "        z = self.d5(z)\n",
    "        #z = 1-F.sigmoid(self.d5(z))\n",
    "        return(z)\n",
    "net = Net().to(device)\n",
    "print(net)\n",
    "params = list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02dce26c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3210197687149048\n",
      "1.2726006507873535\n",
      "1.2539252042770386\n",
      "1.2392131090164185\n",
      "1.2255737781524658\n",
      "1.212024211883545\n",
      "1.2030587196350098\n",
      "1.196172833442688\n",
      "1.1898795366287231\n",
      "1.1836106777191162\n",
      "1.178555965423584\n",
      "1.1747512817382812\n",
      "1.1704554557800293\n",
      "1.1677651405334473\n",
      "1.1645681858062744\n",
      "1.162158489227295\n",
      "1.159623384475708\n",
      "1.1581639051437378\n",
      "1.1523096561431885\n",
      "1.1512298583984375\n",
      "1.1501928567886353\n",
      "1.1476452350616455\n",
      "1.1469002962112427\n",
      "1.1439851522445679\n",
      "1.142114281654358\n",
      "1.1411805152893066\n",
      "1.1391284465789795\n",
      "1.1385890245437622\n",
      "1.1376841068267822\n",
      "1.1372419595718384\n",
      "1.1364721059799194\n",
      "1.1355173587799072\n",
      "1.1348936557769775\n",
      "1.134859323501587\n",
      "1.1339247226715088\n",
      "1.1334311962127686\n",
      "1.1328973770141602\n",
      "1.1324676275253296\n",
      "1.1321693658828735\n",
      "1.1309826374053955\n",
      "1.1306496858596802\n",
      "1.13019597530365\n",
      "1.1290055513381958\n",
      "1.12812340259552\n",
      "1.127753734588623\n",
      "1.1270878314971924\n",
      "1.126759648323059\n",
      "1.1261484622955322\n",
      "1.1258400678634644\n",
      "1.1254547834396362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f45820d9ac0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/icb/manuel.gander/ott_env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[1;32m     13\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr0\u001b[38;5;241m*\u001b[39mgamma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mi\n\u001b[0;32m---> 15\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     16\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(out\u001b[38;5;241m-\u001b[39mvt)\n\u001b[1;32m     17\u001b[0m     your_optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mlist\u001b[39m(net\u001b[38;5;241m.\u001b[39mparameters()), lr\u001b[38;5;241m=\u001b[39mlr)\n",
      "File \u001b[0;32m~/ott_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ott_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 18\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y):\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md1(x))\n\u001b[0;32m---> 18\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md2\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([x,y], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m     z \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md3(z))\n",
      "File \u001b[0;32m~/ott_env/lib/python3.9/site-packages/torch/nn/functional.py:1473\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mean_model_loss = torch.norm(v2t-v2mt)\n",
    "\n",
    "tr_losses = []\n",
    "test_losses = []\n",
    "\n",
    "lr0=1e-2\n",
    "lr1=1e-6\n",
    "steps=10**5\n",
    "gamma=np.exp(np.log(lr1/lr0)/steps)\n",
    "\n",
    "\n",
    "for i in range(steps):\n",
    "    lr=lr0*gamma**i\n",
    "    \n",
    "    out = net(Ct, Dt).flatten()\n",
    "    loss = torch.norm(out-vt)\n",
    "    your_optimizer = optim.Adam(list(net.parameters()), lr=lr)\n",
    "    your_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    your_optimizer.step()\n",
    "    \n",
    "    \n",
    "    if i%10**3==0:\n",
    "        tr_losses.append(float(loss))\n",
    "        out2 = net(C2t, D2t).flatten()\n",
    "        test_loss = torch.norm(out2-v2t)\n",
    "        print(float(test_loss/mean_model_loss))\n",
    "        test_losses.append(float(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1394b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65fe97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5ebacef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.DataFrame({'dataset':dataset, 'n_components':n_components, 'method':method, 'dense_dim':dense_dim,\n",
    "             'tr_losses':tr_losses, 'test_losses':test_losses, 'mean_loss':float(mean_model_loss)})\n",
    "dfs.to_csv(f'{Path}/dr_NN/{dataset}_{n_components}_{method}_{dense_dim}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b0a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162fa24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e38b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53589c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee50a6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
