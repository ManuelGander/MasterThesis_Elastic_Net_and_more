{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef756ec-925d-41cd-92f1-4fbab953b6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                      | 0/24 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "i=4\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/mgander/Atlantic/notebooks/Kinobeads\")\n",
    "import fitter\n",
    "from fitter import process_dfs\n",
    "cols = ['-pec50', 'slope', 'front', 'back', 'fold_change', 'auc', 'rmse', 'r2', 'M1_noise', 'p_err_0', 'p_err_1', 'p_err_2', 'p_err_3', \n",
    "     'p_err_4', 'm0_rmse', 'm1_likelihood', 'm0_likelihood', 'f_statistic', 'p_value']\n",
    "\n",
    "Path='/home/mgander/Atlantic/data/Viability/'\n",
    "\n",
    "M = pd.read_pickle(f'{Path}/M_all_all.pkl')\n",
    "sources = sorted(set(M['Source']))\n",
    "\n",
    "df = M[M['Source']==sources[i]].copy()\n",
    "\n",
    "df['log_dose']=np.log10(df['Dose'])\n",
    "\n",
    "df['key'] = df['Cello']+'_'+df['PubChem_CID']\n",
    "df['key'] = df['key'].astype('category')\n",
    "\n",
    "keys=sorted(set(df['key']))\n",
    "\n",
    "def do_batch(batch):\n",
    "    dfb = df[df['key'].isin(batch)].copy()\n",
    "    dfb['key'] = list(dfb['key'])\n",
    "    dfb['key'] = dfb['key'].astype('category')\n",
    "    all_dfs = [group for _, group in dfb.groupby('key')]\n",
    "\n",
    "    from joblib import Parallel, delayed\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    # Initialize lists to store results\n",
    "    lks = []\n",
    "    ress = []\n",
    "    \n",
    "    # Define the number of jobs\n",
    "    num_jobs = 25  # Set to -1 to use all available cores\n",
    "    \n",
    "    # Parallel processing\n",
    "    results = Parallel(n_jobs=num_jobs)(delayed(process_dfs)(dfs) for dfs in all_dfs)\n",
    "    \n",
    "    # Process the results\n",
    "    for key, res in results:\n",
    "        lks.append(key)\n",
    "        ress.append(res)\n",
    "    return(lks, ress)\n",
    "\n",
    "\n",
    "lks, ress = [], []\n",
    "\n",
    "batchsize = 10**4\n",
    "\n",
    "ks = int(np.ceil(len(keys) / batchsize))\n",
    "\n",
    "for k in tqdm(range(ks)):\n",
    "    batch = keys[k*batchsize:(k+1)*batchsize]\n",
    "    a,b = do_batch(batch)\n",
    "    lks.append(a)\n",
    "    ress.append(b)\n",
    "lks2=[a for b in lks for a in b]\n",
    "ress2=[a for b in ress for a in b]\n",
    "\n",
    "dff=pd.DataFrame(data=np.array(ress2), index=lks2, columns=cols)\n",
    "dff.to_pickle(f'{Path}/dff_gdsc2.pkl')\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd6bc273-68f9-4874-b780-a5ae92dae875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-pec50             4792\n",
       "slope                 0\n",
       "front                 0\n",
       "back                  0\n",
       "fold_change       67477\n",
       "auc                4863\n",
       "rmse                  0\n",
       "r2               234589\n",
       "M1_noise           4792\n",
       "p_err_0            4792\n",
       "p_err_1            4792\n",
       "p_err_2            4792\n",
       "p_err_3               0\n",
       "p_err_4               0\n",
       "m0_rmse               0\n",
       "m1_likelihood    234589\n",
       "m0_likelihood    234589\n",
       "f_statistic           0\n",
       "p_value               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(~np.isfinite(dff)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff80e3b-1dd5-47bd-8b9c-0b5bddf0d536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094dc0b4-5981-4d62-9982-5a587d527d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1665d622-e943-46b5-9283-d18feefdce82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09406b1c-7346-485c-a2d9-c855dd9431c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/mgander/Atlantic/notebooks/Kinobeads\")\n",
    "import fitter\n",
    "from fitter import process_dfs\n",
    "\n",
    "Path='/home/mgander/Atlantic/data/Viability/'\n",
    "dff = pd.read_pickle(f'{Path}/dff_gdsc2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceafd4e5-aa36-400a-b954-0b350a9cf777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-pec50             4792\n",
       "slope                 0\n",
       "front                 0\n",
       "back                  0\n",
       "fold_change       67477\n",
       "auc                4863\n",
       "rmse                  0\n",
       "r2               234589\n",
       "M1_noise           4792\n",
       "p_err_0            4792\n",
       "p_err_1            4792\n",
       "p_err_2            4792\n",
       "p_err_3               0\n",
       "p_err_4               0\n",
       "m0_rmse               0\n",
       "m1_likelihood    234589\n",
       "m0_likelihood    234589\n",
       "f_statistic           0\n",
       "p_value               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(~np.isfinite(dff)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e10b92-55c1-409a-b7cd-f33da1b9c278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c548cd-ebed-4991-be6b-9cccef91370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████▋                                                   | 20/48 [3:38:36<4:20:21, 557.92s/it]"
     ]
    }
   ],
   "source": [
    "i=4\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/mgander/Atlantic/notebooks/Kinobeads\")\n",
    "import fitter_exhaustive\n",
    "from fitter_exhaustive import process_dfs\n",
    "cols = ['-pec50', 'slope', 'front', 'back', 'fold_change', 'auc', 'rmse', 'r2', 'M1_noise', 'p_err_0', 'p_err_1', 'p_err_2', 'p_err_3', \n",
    "     'p_err_4', 'm0_rmse', 'm1_likelihood', 'm0_likelihood', 'f_statistic', 'p_value']\n",
    "\n",
    "Path='/home/mgander/Atlantic/data/Viability/'\n",
    "\n",
    "M = pd.read_pickle(f'{Path}/M_all_all.pkl')\n",
    "sources = sorted(set(M['Source']))\n",
    "\n",
    "df = M[M['Source']==sources[i]].copy()\n",
    "df['log_dose']=np.log10(df['Dose'])\n",
    "\n",
    "df['key'] = df['Cello']+'_'+df['PubChem_CID']\n",
    "df['key'] = df['key'].astype('category')\n",
    "df = df[df['key'].isin(list(dff[~np.isfinite(dff['-pec50'])].index))].copy()\n",
    "\n",
    "keys=sorted(set(df['key']))\n",
    "\n",
    "def do_batch(batch, k):\n",
    "    pd.DataFrame({'k':[k]}).to_csv('tracker.csv')\n",
    "    dfb = df[df['key'].isin(batch)].copy()\n",
    "    dfb['key'] = list(dfb['key'])\n",
    "    dfb['key'] = dfb['key'].astype('category')\n",
    "    all_dfs = [group for _, group in dfb.groupby('key')]\n",
    "\n",
    "    from joblib import Parallel, delayed\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    # Initialize lists to store results\n",
    "    lks = []\n",
    "    ress = []\n",
    "    \n",
    "    # Define the number of jobs\n",
    "    num_jobs = 28  # Set to -1 to use all available cores\n",
    "    \n",
    "    # Parallel processing\n",
    "    results = Parallel(n_jobs=num_jobs)(delayed(process_dfs)(dfs) for dfs in all_dfs)\n",
    "    \n",
    "    # Process the results\n",
    "    for key, res in results:\n",
    "        lks.append(key)\n",
    "        ress.append(res)\n",
    "    return(lks, ress)\n",
    "\n",
    "\n",
    "lks, ress = [], []\n",
    "\n",
    "batchsize = 10**2\n",
    "\n",
    "ks = int(np.ceil(len(keys) / batchsize))\n",
    "\n",
    "for k in tqdm(range(ks)):\n",
    "    batch = keys[k*batchsize:(k+1)*batchsize]\n",
    "    a,b = do_batch(batch, k)\n",
    "    lks.append(a)\n",
    "    ress.append(b)\n",
    "lks2=[a for b in lks for a in b]\n",
    "ress2=[a for b in ress for a in b]\n",
    "\n",
    "dff2=pd.DataFrame(data=np.array(ress2), index=lks2, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b865ee7-598b-41be-b159-4aaf08924f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-pec50             21\n",
       "slope               0\n",
       "front               0\n",
       "back                0\n",
       "fold_change       560\n",
       "auc               152\n",
       "rmse                0\n",
       "r2                  0\n",
       "M1_noise           21\n",
       "p_err_0            21\n",
       "p_err_1            21\n",
       "p_err_2            21\n",
       "p_err_3             0\n",
       "p_err_4             0\n",
       "m0_rmse             0\n",
       "m1_likelihood       0\n",
       "m0_likelihood    4792\n",
       "f_statistic         0\n",
       "p_value             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(~np.isfinite(dff2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c261268-466d-4501-9bab-6375b288dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dffnn =  dff[np.isfinite(dff['-pec50'])].copy()\n",
    "dff666 = pd.concat([dffnn, dff2])\n",
    "dff666.to_pickle(f'{Path}/dff_gdsc2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767074e8-ed4e-4ed8-afd1-40a8a6d439ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a96278-f55b-44dc-a724-f9c1f16f519b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phos",
   "language": "python",
   "name": "phos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
